   | Name                                                                | Type                          | Params
-----------------------------------------------------------------------------------------------------------------------
0  | train_metrics                                                       | ModuleDict                    | 0     
1  | train_metrics.f1score                                               | F1Score                       | 0     
2  | val_metrics                                                         | ModuleDict                    | 0     
3  | val_metrics.f1score                                                 | F1Score                       | 0     
4  | test_metrics                                                        | ModuleDict                    | 0     
5  | test_metrics.f1score                                                | F1Score                       | 0     
6  | adapter                                                             | HuggingFaceAdapter            | 4.4 M 
7  | adapter.model                                                       | BertForSequenceClassification | 4.4 M 
8  | adapter.model.bert                                                  | BertModel                     | 4.4 M 
9  | adapter.model.bert.embeddings                                       | BertEmbeddings                | 4.0 M 
10 | adapter.model.bert.embeddings.word_embeddings                       | Embedding                     | 3.9 M 
11 | adapter.model.bert.embeddings.position_embeddings                   | Embedding                     | 65.5 K
12 | adapter.model.bert.embeddings.token_type_embeddings                 | Embedding                     | 256   
13 | adapter.model.bert.embeddings.LayerNorm                             | LayerNorm                     | 256   
14 | adapter.model.bert.embeddings.dropout                               | Dropout                       | 0     
15 | adapter.model.bert.encoder                                          | BertEncoder                   | 396 K 
16 | adapter.model.bert.encoder.layer                                    | ModuleList                    | 396 K 
17 | adapter.model.bert.encoder.layer.0                                  | BertLayer                     | 198 K 
18 | adapter.model.bert.encoder.layer.0.attention                        | BertAttention                 | 66.3 K
19 | adapter.model.bert.encoder.layer.0.attention.self                   | BertSelfAttention             | 49.5 K
20 | adapter.model.bert.encoder.layer.0.attention.self.query             | Linear                        | 16.5 K
21 | adapter.model.bert.encoder.layer.0.attention.self.key               | Linear                        | 16.5 K
22 | adapter.model.bert.encoder.layer.0.attention.self.value             | Linear                        | 16.5 K
23 | adapter.model.bert.encoder.layer.0.attention.self.dropout           | Dropout                       | 0     
24 | adapter.model.bert.encoder.layer.0.attention.output                 | BertSelfOutput                | 16.8 K
25 | adapter.model.bert.encoder.layer.0.attention.output.dense           | Linear                        | 16.5 K
26 | adapter.model.bert.encoder.layer.0.attention.output.LayerNorm       | LayerNorm                     | 256   
27 | adapter.model.bert.encoder.layer.0.attention.output.dropout         | Dropout                       | 0     
28 | adapter.model.bert.encoder.layer.0.intermediate                     | BertIntermediate              | 66.0 K
29 | adapter.model.bert.encoder.layer.0.intermediate.dense               | Linear                        | 66.0 K
30 | adapter.model.bert.encoder.layer.0.intermediate.intermediate_act_fn | GELUActivation                | 0     
31 | adapter.model.bert.encoder.layer.0.output                           | BertOutput                    | 65.9 K
32 | adapter.model.bert.encoder.layer.0.output.dense                     | Linear                        | 65.7 K
33 | adapter.model.bert.encoder.layer.0.output.LayerNorm                 | LayerNorm                     | 256   
34 | adapter.model.bert.encoder.layer.0.output.dropout                   | Dropout                       | 0     
35 | adapter.model.bert.encoder.layer.1                                  | BertLayer                     | 198 K 
36 | adapter.model.bert.encoder.layer.1.attention                        | BertAttention                 | 66.3 K
37 | adapter.model.bert.encoder.layer.1.attention.self                   | BertSelfAttention             | 49.5 K
38 | adapter.model.bert.encoder.layer.1.attention.self.query             | Linear                        | 16.5 K
39 | adapter.model.bert.encoder.layer.1.attention.self.key               | Linear                        | 16.5 K
40 | adapter.model.bert.encoder.layer.1.attention.self.value             | Linear                        | 16.5 K
41 | adapter.model.bert.encoder.layer.1.attention.self.dropout           | Dropout                       | 0     
42 | adapter.model.bert.encoder.layer.1.attention.output                 | BertSelfOutput                | 16.8 K
43 | adapter.model.bert.encoder.layer.1.attention.output.dense           | Linear                        | 16.5 K
44 | adapter.model.bert.encoder.layer.1.attention.output.LayerNorm       | LayerNorm                     | 256   
45 | adapter.model.bert.encoder.layer.1.attention.output.dropout         | Dropout                       | 0     
46 | adapter.model.bert.encoder.layer.1.intermediate                     | BertIntermediate              | 66.0 K
47 | adapter.model.bert.encoder.layer.1.intermediate.dense               | Linear                        | 66.0 K
48 | adapter.model.bert.encoder.layer.1.intermediate.intermediate_act_fn | GELUActivation                | 0     
49 | adapter.model.bert.encoder.layer.1.output                           | BertOutput                    | 65.9 K
50 | adapter.model.bert.encoder.layer.1.output.dense                     | Linear                        | 65.7 K
51 | adapter.model.bert.encoder.layer.1.output.LayerNorm                 | LayerNorm                     | 256   
52 | adapter.model.bert.encoder.layer.1.output.dropout                   | Dropout                       | 0     
53 | adapter.model.bert.pooler                                           | BertPooler                    | 16.5 K
54 | adapter.model.bert.pooler.dense                                     | Linear                        | 16.5 K
55 | adapter.model.bert.pooler.activation                                | Tanh                          | 0     
56 | adapter.model.dropout                                               | Dropout                       | 0     
57 | adapter.model.classifier                                            | Linear                        | 258   
-----------------------------------------------------------------------------------------------------------------------
258       Trainable params
4.4 M     Non-trainable params
4.4 M     Total params
17.545    Total estimated model params size (MB)